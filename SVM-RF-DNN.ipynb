{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (59381, 128)\n",
      "test: (19765, 127)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print(\"train:\", train.shape)\n",
    "print(\"test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id' 'Product_Info_1' 'Product_Info_2' 'Product_Info_3' 'Product_Info_4'\n",
      " 'Product_Info_5' 'Product_Info_6' 'Product_Info_7' 'Ins_Age' 'Ht' 'Wt'\n",
      " 'BMI' 'Employment_Info_1' 'Employment_Info_2' 'Employment_Info_3'\n",
      " 'Employment_Info_4' 'Employment_Info_5' 'Employment_Info_6'\n",
      " 'InsuredInfo_1' 'InsuredInfo_2' 'InsuredInfo_3' 'InsuredInfo_4'\n",
      " 'InsuredInfo_5' 'InsuredInfo_6' 'InsuredInfo_7' 'Insurance_History_1'\n",
      " 'Insurance_History_2' 'Insurance_History_3' 'Insurance_History_4'\n",
      " 'Insurance_History_5' 'Insurance_History_7' 'Insurance_History_8'\n",
      " 'Insurance_History_9' 'Family_Hist_1' 'Family_Hist_2' 'Family_Hist_3'\n",
      " 'Family_Hist_4' 'Family_Hist_5' 'Medical_History_1' 'Medical_History_2'\n",
      " 'Medical_History_3' 'Medical_History_4' 'Medical_History_5'\n",
      " 'Medical_History_6' 'Medical_History_7' 'Medical_History_8'\n",
      " 'Medical_History_9' 'Medical_History_10' 'Medical_History_11'\n",
      " 'Medical_History_12' 'Medical_History_13' 'Medical_History_14'\n",
      " 'Medical_History_15' 'Medical_History_16' 'Medical_History_17'\n",
      " 'Medical_History_18' 'Medical_History_19' 'Medical_History_20'\n",
      " 'Medical_History_21' 'Medical_History_22' 'Medical_History_23'\n",
      " 'Medical_History_24' 'Medical_History_25' 'Medical_History_26'\n",
      " 'Medical_History_27' 'Medical_History_28' 'Medical_History_29'\n",
      " 'Medical_History_30' 'Medical_History_31' 'Medical_History_32'\n",
      " 'Medical_History_33' 'Medical_History_34' 'Medical_History_35'\n",
      " 'Medical_History_36' 'Medical_History_37' 'Medical_History_38'\n",
      " 'Medical_History_39' 'Medical_History_40' 'Medical_History_41'\n",
      " 'Medical_Keyword_1' 'Medical_Keyword_2' 'Medical_Keyword_3'\n",
      " 'Medical_Keyword_4' 'Medical_Keyword_5' 'Medical_Keyword_6'\n",
      " 'Medical_Keyword_7' 'Medical_Keyword_8' 'Medical_Keyword_9'\n",
      " 'Medical_Keyword_10' 'Medical_Keyword_11' 'Medical_Keyword_12'\n",
      " 'Medical_Keyword_13' 'Medical_Keyword_14' 'Medical_Keyword_15'\n",
      " 'Medical_Keyword_16' 'Medical_Keyword_17' 'Medical_Keyword_18'\n",
      " 'Medical_Keyword_19' 'Medical_Keyword_20' 'Medical_Keyword_21'\n",
      " 'Medical_Keyword_22' 'Medical_Keyword_23' 'Medical_Keyword_24'\n",
      " 'Medical_Keyword_25' 'Medical_Keyword_26' 'Medical_Keyword_27'\n",
      " 'Medical_Keyword_28' 'Medical_Keyword_29' 'Medical_Keyword_30'\n",
      " 'Medical_Keyword_31' 'Medical_Keyword_32' 'Medical_Keyword_33'\n",
      " 'Medical_Keyword_34' 'Medical_Keyword_35' 'Medical_Keyword_36'\n",
      " 'Medical_Keyword_37' 'Medical_Keyword_38' 'Medical_Keyword_39'\n",
      " 'Medical_Keyword_40' 'Medical_Keyword_41' 'Medical_Keyword_42'\n",
      " 'Medical_Keyword_43' 'Medical_Keyword_44' 'Medical_Keyword_45'\n",
      " 'Medical_Keyword_46' 'Medical_Keyword_47' 'Medical_Keyword_48' 'Response']\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(train.columns.to_numpy())\n",
    "#pdp.ProfileReport(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    19489\n",
      "6    11233\n",
      "7     8027\n",
      "2     6552\n",
      "1     6207\n",
      "5     5432\n",
      "4     1428\n",
      "3     1013\n",
      "Name: Response, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split x and y\n",
    "x = train.iloc[:,1:-1]\n",
    "y = train['Response']\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59381, 144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode categorical data \n",
    "x = pd.get_dummies(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_Info_2_B2</th>\n",
       "      <th>Product_Info_2_C1</th>\n",
       "      <th>Product_Info_2_C2</th>\n",
       "      <th>Product_Info_2_C3</th>\n",
       "      <th>Product_Info_2_C4</th>\n",
       "      <th>Product_Info_2_D1</th>\n",
       "      <th>Product_Info_2_D2</th>\n",
       "      <th>Product_Info_2_D3</th>\n",
       "      <th>Product_Info_2_D4</th>\n",
       "      <th>Product_Info_2_E1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>-2.264385</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>1.197962</td>\n",
       "      <td>-1.690031</td>\n",
       "      <td>-1.617886</td>\n",
       "      <td>-1.198363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>1.773817</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.753982</td>\n",
       "      <td>-1.445119</td>\n",
       "      <td>-1.805858</td>\n",
       "      <td>-1.613382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.905363</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>-0.332879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>4.629613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>0.559979</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.224146</td>\n",
       "      <td>-0.465473</td>\n",
       "      <td>-0.983481</td>\n",
       "      <td>-0.957553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>2.119467</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.062599</td>\n",
       "      <td>-0.710384</td>\n",
       "      <td>-0.654530</td>\n",
       "      <td>-0.371621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>2.906295</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59376</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.678291</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.308826</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>2.839061</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59377</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>1.248909</td>\n",
       "      <td>1.248685</td>\n",
       "      <td>0.668157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>1.773817</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59378</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.526909</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>-0.513551</td>\n",
       "      <td>-0.887749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>4.629613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59379</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.516744</td>\n",
       "      <td>-0.220561</td>\n",
       "      <td>-0.184601</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>2.906295</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59380</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.213980</td>\n",
       "      <td>1.003997</td>\n",
       "      <td>1.013720</td>\n",
       "      <td>0.573602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59381 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Product_Info_1  Product_Info_3  Product_Info_4  Product_Info_5  \\\n",
       "0           -0.164525       -2.841731       -0.891949       -0.083689   \n",
       "1           -0.164525        0.312319       -0.891949       -0.083689   \n",
       "2           -0.164525        0.312319       -0.891949       -0.083689   \n",
       "3           -0.164525       -2.841731        0.559979       -0.083689   \n",
       "4           -0.164525        0.312319       -0.347476       -0.083689   \n",
       "...               ...             ...             ...             ...   \n",
       "59376       -0.164525       -2.841731       -0.347476       -0.083689   \n",
       "59377       -0.164525        0.312319       -0.347476       -0.083689   \n",
       "59378       -0.164525        0.312319       -0.891949       -0.083689   \n",
       "59379       -0.164525       -2.841731       -0.347476       -0.083689   \n",
       "59380       -0.164525        0.312319       -0.891949       -0.083689   \n",
       "\n",
       "       Product_Info_6  Product_Info_7   Ins_Age        Ht        Wt       BMI  \\\n",
       "0           -2.264385       -0.149284  1.197962 -1.690031 -1.617886 -1.198363   \n",
       "1            0.441621       -0.149284 -1.753982 -1.445119 -1.805858 -1.613382   \n",
       "2            0.441621       -0.149284 -1.905363  0.514174 -0.043622 -0.332879   \n",
       "3            0.441621       -0.149284 -1.224146 -0.465473 -0.983481 -0.957553   \n",
       "4            0.441621       -0.149284  0.062599 -0.710384 -0.654530 -0.371621   \n",
       "...               ...             ...       ...       ...       ...       ...   \n",
       "59376        0.441621       -0.149284 -1.678291  0.024351  0.308826  0.406188   \n",
       "59377        0.441621       -0.149284  0.138290  1.248909  1.248685  0.668157   \n",
       "59378        0.441621       -0.149284 -1.526909  0.514174 -0.513551 -0.887749   \n",
       "59379        0.441621       -0.149284  0.516744 -0.220561 -0.184601 -0.057360   \n",
       "59380        0.441621       -0.149284  0.213980  1.003997  1.013720  0.573602   \n",
       "\n",
       "       ...  Product_Info_2_B2  Product_Info_2_C1  Product_Info_2_C2  \\\n",
       "0      ...          -0.138776          -0.069445          -0.051978   \n",
       "1      ...          -0.138776          -0.069445          -0.051978   \n",
       "2      ...          -0.138776          -0.069445          -0.051978   \n",
       "3      ...          -0.138776          -0.069445          -0.051978   \n",
       "4      ...          -0.138776          -0.069445          -0.051978   \n",
       "...    ...                ...                ...                ...   \n",
       "59376  ...          -0.138776          -0.069445          -0.051978   \n",
       "59377  ...          -0.138776          -0.069445          -0.051978   \n",
       "59378  ...          -0.138776          -0.069445          -0.051978   \n",
       "59379  ...          -0.138776          -0.069445          -0.051978   \n",
       "59380  ...          -0.138776          -0.069445          -0.051978   \n",
       "\n",
       "       Product_Info_2_C3  Product_Info_2_C4  Product_Info_2_D1  \\\n",
       "0              -0.071971          -0.060842          -0.352229   \n",
       "1              -0.071971          -0.060842          -0.352229   \n",
       "2              -0.071971          -0.060842          -0.352229   \n",
       "3              -0.071971          -0.060842          -0.352229   \n",
       "4              -0.071971          -0.060842          -0.352229   \n",
       "...                  ...                ...                ...   \n",
       "59376          -0.071971          -0.060842           2.839061   \n",
       "59377          -0.071971          -0.060842          -0.352229   \n",
       "59378          -0.071971          -0.060842          -0.352229   \n",
       "59379          -0.071971          -0.060842          -0.352229   \n",
       "59380          -0.071971          -0.060842          -0.352229   \n",
       "\n",
       "       Product_Info_2_D2  Product_Info_2_D3  Product_Info_2_D4  \\\n",
       "0              -0.344081           1.773817          -0.471817   \n",
       "1              -0.344081          -0.563756          -0.471817   \n",
       "2              -0.344081          -0.563756          -0.471817   \n",
       "3              -0.344081          -0.563756           2.119467   \n",
       "4               2.906295          -0.563756          -0.471817   \n",
       "...                  ...                ...                ...   \n",
       "59376          -0.344081          -0.563756          -0.471817   \n",
       "59377          -0.344081           1.773817          -0.471817   \n",
       "59378          -0.344081          -0.563756          -0.471817   \n",
       "59379           2.906295          -0.563756          -0.471817   \n",
       "59380          -0.344081          -0.563756          -0.471817   \n",
       "\n",
       "       Product_Info_2_E1  \n",
       "0              -0.216001  \n",
       "1              -0.216001  \n",
       "2               4.629613  \n",
       "3              -0.216001  \n",
       "4              -0.216001  \n",
       "...                  ...  \n",
       "59376          -0.216001  \n",
       "59377          -0.216001  \n",
       "59378           4.629613  \n",
       "59379          -0.216001  \n",
       "59380          -0.216001  \n",
       "\n",
       "[59381 rows x 144 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_Info_2_B2</th>\n",
       "      <th>Product_Info_2_C1</th>\n",
       "      <th>Product_Info_2_C2</th>\n",
       "      <th>Product_Info_2_C3</th>\n",
       "      <th>Product_Info_2_C4</th>\n",
       "      <th>Product_Info_2_D1</th>\n",
       "      <th>Product_Info_2_D2</th>\n",
       "      <th>Product_Info_2_D3</th>\n",
       "      <th>Product_Info_2_D4</th>\n",
       "      <th>Product_Info_2_E1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>-2.264385</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>1.197962</td>\n",
       "      <td>-1.690031</td>\n",
       "      <td>-1.617886</td>\n",
       "      <td>-1.198363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>1.773817</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.753982</td>\n",
       "      <td>-1.445119</td>\n",
       "      <td>-1.805858</td>\n",
       "      <td>-1.613382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.905363</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>-0.332879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>4.629613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>0.559979</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.224146</td>\n",
       "      <td>-0.465473</td>\n",
       "      <td>-0.983481</td>\n",
       "      <td>-0.957553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>2.119467</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.062599</td>\n",
       "      <td>-0.710384</td>\n",
       "      <td>-0.654530</td>\n",
       "      <td>-0.371621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>2.906295</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59376</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.678291</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.308826</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>2.839061</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59377</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>1.248909</td>\n",
       "      <td>1.248685</td>\n",
       "      <td>0.668157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>1.773817</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59378</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>-1.526909</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>-0.513551</td>\n",
       "      <td>-0.887749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>4.629613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59379</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-2.841731</td>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.516744</td>\n",
       "      <td>-0.220561</td>\n",
       "      <td>-0.184601</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>2.906295</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59380</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.083689</td>\n",
       "      <td>0.441621</td>\n",
       "      <td>-0.149284</td>\n",
       "      <td>0.213980</td>\n",
       "      <td>1.003997</td>\n",
       "      <td>1.013720</td>\n",
       "      <td>0.573602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>-0.069445</td>\n",
       "      <td>-0.051978</td>\n",
       "      <td>-0.071971</td>\n",
       "      <td>-0.060842</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.563756</td>\n",
       "      <td>-0.471817</td>\n",
       "      <td>-0.216001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59381 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Product_Info_1  Product_Info_3  Product_Info_4  Product_Info_5  \\\n",
       "0           -0.164525       -2.841731       -0.891949       -0.083689   \n",
       "1           -0.164525        0.312319       -0.891949       -0.083689   \n",
       "2           -0.164525        0.312319       -0.891949       -0.083689   \n",
       "3           -0.164525       -2.841731        0.559979       -0.083689   \n",
       "4           -0.164525        0.312319       -0.347476       -0.083689   \n",
       "...               ...             ...             ...             ...   \n",
       "59376       -0.164525       -2.841731       -0.347476       -0.083689   \n",
       "59377       -0.164525        0.312319       -0.347476       -0.083689   \n",
       "59378       -0.164525        0.312319       -0.891949       -0.083689   \n",
       "59379       -0.164525       -2.841731       -0.347476       -0.083689   \n",
       "59380       -0.164525        0.312319       -0.891949       -0.083689   \n",
       "\n",
       "       Product_Info_6  Product_Info_7   Ins_Age        Ht        Wt       BMI  \\\n",
       "0           -2.264385       -0.149284  1.197962 -1.690031 -1.617886 -1.198363   \n",
       "1            0.441621       -0.149284 -1.753982 -1.445119 -1.805858 -1.613382   \n",
       "2            0.441621       -0.149284 -1.905363  0.514174 -0.043622 -0.332879   \n",
       "3            0.441621       -0.149284 -1.224146 -0.465473 -0.983481 -0.957553   \n",
       "4            0.441621       -0.149284  0.062599 -0.710384 -0.654530 -0.371621   \n",
       "...               ...             ...       ...       ...       ...       ...   \n",
       "59376        0.441621       -0.149284 -1.678291  0.024351  0.308826  0.406188   \n",
       "59377        0.441621       -0.149284  0.138290  1.248909  1.248685  0.668157   \n",
       "59378        0.441621       -0.149284 -1.526909  0.514174 -0.513551 -0.887749   \n",
       "59379        0.441621       -0.149284  0.516744 -0.220561 -0.184601 -0.057360   \n",
       "59380        0.441621       -0.149284  0.213980  1.003997  1.013720  0.573602   \n",
       "\n",
       "       ...  Product_Info_2_B2  Product_Info_2_C1  Product_Info_2_C2  \\\n",
       "0      ...          -0.138776          -0.069445          -0.051978   \n",
       "1      ...          -0.138776          -0.069445          -0.051978   \n",
       "2      ...          -0.138776          -0.069445          -0.051978   \n",
       "3      ...          -0.138776          -0.069445          -0.051978   \n",
       "4      ...          -0.138776          -0.069445          -0.051978   \n",
       "...    ...                ...                ...                ...   \n",
       "59376  ...          -0.138776          -0.069445          -0.051978   \n",
       "59377  ...          -0.138776          -0.069445          -0.051978   \n",
       "59378  ...          -0.138776          -0.069445          -0.051978   \n",
       "59379  ...          -0.138776          -0.069445          -0.051978   \n",
       "59380  ...          -0.138776          -0.069445          -0.051978   \n",
       "\n",
       "       Product_Info_2_C3  Product_Info_2_C4  Product_Info_2_D1  \\\n",
       "0              -0.071971          -0.060842          -0.352229   \n",
       "1              -0.071971          -0.060842          -0.352229   \n",
       "2              -0.071971          -0.060842          -0.352229   \n",
       "3              -0.071971          -0.060842          -0.352229   \n",
       "4              -0.071971          -0.060842          -0.352229   \n",
       "...                  ...                ...                ...   \n",
       "59376          -0.071971          -0.060842           2.839061   \n",
       "59377          -0.071971          -0.060842          -0.352229   \n",
       "59378          -0.071971          -0.060842          -0.352229   \n",
       "59379          -0.071971          -0.060842          -0.352229   \n",
       "59380          -0.071971          -0.060842          -0.352229   \n",
       "\n",
       "       Product_Info_2_D2  Product_Info_2_D3  Product_Info_2_D4  \\\n",
       "0              -0.344081           1.773817          -0.471817   \n",
       "1              -0.344081          -0.563756          -0.471817   \n",
       "2              -0.344081          -0.563756          -0.471817   \n",
       "3              -0.344081          -0.563756           2.119467   \n",
       "4               2.906295          -0.563756          -0.471817   \n",
       "...                  ...                ...                ...   \n",
       "59376          -0.344081          -0.563756          -0.471817   \n",
       "59377          -0.344081           1.773817          -0.471817   \n",
       "59378          -0.344081          -0.563756          -0.471817   \n",
       "59379           2.906295          -0.563756          -0.471817   \n",
       "59380          -0.344081          -0.563756          -0.471817   \n",
       "\n",
       "       Product_Info_2_E1  \n",
       "0              -0.216001  \n",
       "1              -0.216001  \n",
       "2               4.629613  \n",
       "3              -0.216001  \n",
       "4              -0.216001  \n",
       "...                  ...  \n",
       "59376          -0.216001  \n",
       "59377          -0.216001  \n",
       "59378           4.629613  \n",
       "59379          -0.216001  \n",
       "59380          -0.216001  \n",
       "\n",
       "[59381 rows x 144 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "x = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "z = test.iloc[:,1:]\n",
    "z = pd.get_dummies(z)\n",
    "z = pd.DataFrame(scaler.transform(z), columns=z.columns)\n",
    "z = pd.DataFrame(imputer.transform(z), columns=z.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44535, 144) (14846, 144) (44535,) (14846,)\n"
     ]
    }
   ],
   "source": [
    "# Split train data and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, random_state=0)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "[CV] C=5, dual=False, penalty=l1 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=5, dual=False, penalty=l1, total= 3.1min\n",
      "[CV] C=5, dual=False, penalty=l1 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=5, dual=False, penalty=l1, total= 2.9min\n",
      "[CV] C=5, dual=False, penalty=l1 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=5, dual=False, penalty=l1, total= 3.3min\n",
      "[CV] C=5, dual=False, penalty=l1 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=5, dual=False, penalty=l1, total= 2.9min\n",
      "[CV] C=5, dual=False, penalty=l2 .....................................\n",
      "[CV] ...................... C=5, dual=False, penalty=l2, total=  21.6s\n",
      "[CV] C=5, dual=False, penalty=l2 .....................................\n",
      "[CV] ...................... C=5, dual=False, penalty=l2, total=  22.0s\n",
      "[CV] C=5, dual=False, penalty=l2 .....................................\n",
      "[CV] ...................... C=5, dual=False, penalty=l2, total=  24.1s\n",
      "[CV] C=5, dual=False, penalty=l2 .....................................\n",
      "[CV] ...................... C=5, dual=False, penalty=l2, total=  23.9s\n",
      "[CV] C=10, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, dual=False, penalty=l1, total= 3.2min\n",
      "[CV] C=10, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, dual=False, penalty=l1, total= 2.7min\n",
      "[CV] C=10, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, dual=False, penalty=l1, total= 2.6min\n",
      "[CV] C=10, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, dual=False, penalty=l1, total= 3.0min\n",
      "[CV] C=10, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=10, dual=False, penalty=l2, total=  21.9s\n",
      "[CV] C=10, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=10, dual=False, penalty=l2, total=  21.8s\n",
      "[CV] C=10, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=10, dual=False, penalty=l2, total=  20.7s\n",
      "[CV] C=10, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=10, dual=False, penalty=l2, total=  22.6s\n",
      "[CV] C=20, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=20, dual=False, penalty=l1, total= 2.6min\n",
      "[CV] C=20, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=20, dual=False, penalty=l1, total= 2.7min\n",
      "[CV] C=20, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=20, dual=False, penalty=l1, total= 2.6min\n",
      "[CV] C=20, dual=False, penalty=l1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=20, dual=False, penalty=l1, total= 3.5min\n",
      "[CV] C=20, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=20, dual=False, penalty=l2, total=  22.0s\n",
      "[CV] C=20, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=20, dual=False, penalty=l2, total=  21.4s\n",
      "[CV] C=20, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=20, dual=False, penalty=l2, total=  21.7s\n",
      "[CV] C=20, dual=False, penalty=l2 ....................................\n",
      "[CV] ..................... C=20, dual=False, penalty=l2, total=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 39.5min finished\n",
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182.094092</td>\n",
       "      <td>9.551927</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 5, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>0.506197</td>\n",
       "      <td>0.505086</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503402</td>\n",
       "      <td>0.505195</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.900598</td>\n",
       "      <td>1.117092</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 5, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>0.505928</td>\n",
       "      <td>0.505019</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503402</td>\n",
       "      <td>0.505111</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172.657610</td>\n",
       "      <td>14.278640</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>0.506130</td>\n",
       "      <td>0.505019</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503334</td>\n",
       "      <td>0.505145</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.705806</td>\n",
       "      <td>0.693742</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>0.505928</td>\n",
       "      <td>0.505086</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503402</td>\n",
       "      <td>0.505128</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.321836</td>\n",
       "      <td>23.387452</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 20, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>0.506062</td>\n",
       "      <td>0.505019</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503402</td>\n",
       "      <td>0.505145</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.897235</td>\n",
       "      <td>0.451046</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 20, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>0.505928</td>\n",
       "      <td>0.505086</td>\n",
       "      <td>0.506096</td>\n",
       "      <td>0.503402</td>\n",
       "      <td>0.505128</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     182.094092      9.551927         0.011709        0.012942       5   \n",
       "1      22.900598      1.117092         0.015620        0.000002       5   \n",
       "2     172.657610     14.278640         0.011716        0.006764      10   \n",
       "3      21.705806      0.693742         0.011719        0.006766      10   \n",
       "4     171.321836     23.387452         0.007803        0.007803      20   \n",
       "5      21.897235      0.451046         0.011716        0.006764      20   \n",
       "\n",
       "  param_dual param_penalty                                     params  \\\n",
       "0      False            l1   {'C': 5, 'dual': False, 'penalty': 'l1'}   \n",
       "1      False            l2   {'C': 5, 'dual': False, 'penalty': 'l2'}   \n",
       "2      False            l1  {'C': 10, 'dual': False, 'penalty': 'l1'}   \n",
       "3      False            l2  {'C': 10, 'dual': False, 'penalty': 'l2'}   \n",
       "4      False            l1  {'C': 20, 'dual': False, 'penalty': 'l1'}   \n",
       "5      False            l2  {'C': 20, 'dual': False, 'penalty': 'l2'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.506197           0.505086           0.506096           0.503402   \n",
       "1           0.505928           0.505019           0.506096           0.503402   \n",
       "2           0.506130           0.505019           0.506096           0.503334   \n",
       "3           0.505928           0.505086           0.506096           0.503402   \n",
       "4           0.506062           0.505019           0.506096           0.503402   \n",
       "5           0.505928           0.505086           0.506096           0.503402   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.505195        0.001123                1  \n",
       "1         0.505111        0.001069                6  \n",
       "2         0.505145        0.001137                3  \n",
       "3         0.505128        0.001068                4  \n",
       "4         0.505145        0.001096                2  \n",
       "5         0.505128        0.001068                4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM (grid search)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "param = {'C': [5, 10, 20], 'dual': [False], 'penalty': ['l1', 'l2']}\n",
    "gscv = GridSearchCV(LinearSVC(), param, cv=4, verbose=2)\n",
    "gscv.fit(x, y)\n",
    "\n",
    "result = pd.DataFrame.from_dict(gscv.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM (train)\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(C=10, penalty='l1', dual=False)\n",
    "svm_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "filename = 'svm_clf.bin'\n",
    "pickle.dump(svm_clf, open(filename, 'wb'))\n",
    "\n",
    "# Load model\n",
    "#model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=50, random_state=0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=15, n_estimators=50, random_state=0, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=50, random_state=0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=15, n_estimators=50, random_state=0, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=50, random_state=0, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=50, random_state=0, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=75, random_state=0, total=   6.3s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=75, random_state=0, total=   5.9s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=75, random_state=0, total=   5.9s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=75, random_state=0, total=   5.9s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=100, random_state=0, total=   9.0s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=100, random_state=0, total=   8.4s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=100, random_state=0, total=   8.0s\n",
      "[CV] criterion=gini, max_depth=15, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=15, n_estimators=100, random_state=0, total=   9.5s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=50, random_state=0, total=   6.9s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=50, random_state=0, total=   5.5s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=50, random_state=0, total=   5.3s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=50, random_state=0, total=   6.4s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=75, random_state=0, total=   9.9s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=75, random_state=0, total=  10.3s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=75, random_state=0, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=75, random_state=0, total=   8.5s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=100, random_state=0, total=  12.6s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=100, random_state=0, total=  12.8s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=100, random_state=0, total=  11.1s\n",
      "[CV] criterion=gini, max_depth=20, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=20, n_estimators=100, random_state=0, total=  13.0s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=50, random_state=0, total=   7.7s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=50, random_state=0, total=   6.8s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=50, random_state=0, total=   7.0s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=50, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=50, random_state=0, total=   7.9s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=75, random_state=0, total=  11.7s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=75, random_state=0, total=  11.7s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=75, random_state=0, total=  11.8s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=75, random_state=0 ...\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=75, random_state=0, total=  11.7s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=100, random_state=0, total=  15.5s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=100, random_state=0, total=  15.7s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=100, random_state=0, total=  15.6s\n",
      "[CV] criterion=gini, max_depth=25, n_estimators=100, random_state=0 ..\n",
      "[CV]  criterion=gini, max_depth=25, n_estimators=100, random_state=0, total=  15.6s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=50, random_state=0, total=   5.8s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=50, random_state=0, total=   5.7s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=50, random_state=0, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=50, random_state=0, total=   4.7s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=75, random_state=0, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=75, random_state=0, total=   8.7s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=75, random_state=0, total=   8.6s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=75, random_state=0, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=100, random_state=0, total=  10.2s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=100, random_state=0, total=  10.6s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=100, random_state=0, total=  10.7s\n",
      "[CV] criterion=entropy, max_depth=15, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=15, n_estimators=100, random_state=0, total=  10.1s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=50, random_state=0, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=50, random_state=0, total=   7.0s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=50, random_state=0, total=   7.0s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=50, random_state=0, total=   8.6s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=75, random_state=0, total=  13.8s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=75, random_state=0, total=  12.2s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=75, random_state=0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=20, n_estimators=75, random_state=0, total=  12.7s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=75, random_state=0, total=  11.6s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=100, random_state=0, total=  17.3s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=100, random_state=0, total=  15.6s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=100, random_state=0, total=  14.3s\n",
      "[CV] criterion=entropy, max_depth=20, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=20, n_estimators=100, random_state=0, total=  13.3s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=50, random_state=0, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=50, random_state=0, total=   8.2s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=50, random_state=0, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=50, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=50, random_state=0, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=75, random_state=0, total=  12.1s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=75, random_state=0, total=  11.7s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=75, random_state=0, total=  11.4s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=75, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=75, random_state=0, total=  11.3s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=100, random_state=0, total=  17.3s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=100, random_state=0, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=100, random_state=0, total=  18.9s\n",
      "[CV] criterion=entropy, max_depth=25, n_estimators=100, random_state=0 \n",
      "[CV]  criterion=entropy, max_depth=25, n_estimators=100, random_state=0, total=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.852139</td>\n",
       "      <td>0.083060</td>\n",
       "      <td>0.179726</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 15, 'n_esti...</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>0.560189</td>\n",
       "      <td>0.558639</td>\n",
       "      <td>0.556416</td>\n",
       "      <td>0.558664</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.757393</td>\n",
       "      <td>0.194845</td>\n",
       "      <td>0.238235</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 15, 'n_esti...</td>\n",
       "      <td>0.561902</td>\n",
       "      <td>0.562883</td>\n",
       "      <td>0.561401</td>\n",
       "      <td>0.561401</td>\n",
       "      <td>0.561897</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.361337</td>\n",
       "      <td>0.540947</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 15, 'n_esti...</td>\n",
       "      <td>0.562710</td>\n",
       "      <td>0.562748</td>\n",
       "      <td>0.562883</td>\n",
       "      <td>0.561132</td>\n",
       "      <td>0.562368</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.783798</td>\n",
       "      <td>0.652210</td>\n",
       "      <td>0.234329</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "      <td>0.565607</td>\n",
       "      <td>0.563355</td>\n",
       "      <td>0.567868</td>\n",
       "      <td>0.563826</td>\n",
       "      <td>0.565164</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.974468</td>\n",
       "      <td>0.721167</td>\n",
       "      <td>0.363205</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "      <td>0.568032</td>\n",
       "      <td>0.569485</td>\n",
       "      <td>0.570562</td>\n",
       "      <td>0.563355</td>\n",
       "      <td>0.567858</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.860507</td>\n",
       "      <td>0.753991</td>\n",
       "      <td>0.511605</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "      <td>0.569110</td>\n",
       "      <td>0.571371</td>\n",
       "      <td>0.572044</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.570182</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.064764</td>\n",
       "      <td>0.429133</td>\n",
       "      <td>0.292892</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 25, 'n_esti...</td>\n",
       "      <td>0.566483</td>\n",
       "      <td>0.564904</td>\n",
       "      <td>0.564837</td>\n",
       "      <td>0.561334</td>\n",
       "      <td>0.564389</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.278615</td>\n",
       "      <td>0.050621</td>\n",
       "      <td>0.449117</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 25, 'n_esti...</td>\n",
       "      <td>0.568840</td>\n",
       "      <td>0.570967</td>\n",
       "      <td>0.570226</td>\n",
       "      <td>0.563759</td>\n",
       "      <td>0.568448</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.016027</td>\n",
       "      <td>0.072746</td>\n",
       "      <td>0.609230</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 25, 'n_esti...</td>\n",
       "      <td>0.571063</td>\n",
       "      <td>0.575076</td>\n",
       "      <td>0.570293</td>\n",
       "      <td>0.567262</td>\n",
       "      <td>0.570923</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.115995</td>\n",
       "      <td>0.458709</td>\n",
       "      <td>0.187456</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 15, 'n_e...</td>\n",
       "      <td>0.553887</td>\n",
       "      <td>0.554665</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>0.555312</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.798960</td>\n",
       "      <td>0.542535</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 15, 'n_e...</td>\n",
       "      <td>0.557457</td>\n",
       "      <td>0.557966</td>\n",
       "      <td>0.563422</td>\n",
       "      <td>0.558302</td>\n",
       "      <td>0.559287</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.065815</td>\n",
       "      <td>0.243680</td>\n",
       "      <td>0.339774</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 15, 'n_e...</td>\n",
       "      <td>0.559949</td>\n",
       "      <td>0.560997</td>\n",
       "      <td>0.565173</td>\n",
       "      <td>0.560121</td>\n",
       "      <td>0.561560</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.269990</td>\n",
       "      <td>0.628429</td>\n",
       "      <td>0.258173</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_e...</td>\n",
       "      <td>0.559477</td>\n",
       "      <td>0.561603</td>\n",
       "      <td>0.562479</td>\n",
       "      <td>0.559380</td>\n",
       "      <td>0.560735</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.120765</td>\n",
       "      <td>0.830377</td>\n",
       "      <td>0.429572</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_e...</td>\n",
       "      <td>0.563654</td>\n",
       "      <td>0.566386</td>\n",
       "      <td>0.567599</td>\n",
       "      <td>0.564230</td>\n",
       "      <td>0.565467</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.585749</td>\n",
       "      <td>1.422950</td>\n",
       "      <td>0.538901</td>\n",
       "      <td>0.099106</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_e...</td>\n",
       "      <td>0.565674</td>\n",
       "      <td>0.568070</td>\n",
       "      <td>0.567060</td>\n",
       "      <td>0.563894</td>\n",
       "      <td>0.566174</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.435436</td>\n",
       "      <td>0.317254</td>\n",
       "      <td>0.257725</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.562778</td>\n",
       "      <td>0.563085</td>\n",
       "      <td>0.563624</td>\n",
       "      <td>0.561469</td>\n",
       "      <td>0.562739</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.199969</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.413954</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.568032</td>\n",
       "      <td>0.565376</td>\n",
       "      <td>0.569148</td>\n",
       "      <td>0.564365</td>\n",
       "      <td>0.566730</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.705971</td>\n",
       "      <td>0.608757</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.023083</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.568099</td>\n",
       "      <td>0.570293</td>\n",
       "      <td>0.571640</td>\n",
       "      <td>0.565039</td>\n",
       "      <td>0.568768</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        3.852139      0.083060         0.179726        0.032210   \n",
       "1        5.757393      0.194845         0.238235        0.006743   \n",
       "2        8.361337      0.540947         0.359300        0.033142   \n",
       "3        5.783798      0.652210         0.234329        0.027052   \n",
       "4        8.974468      0.721167         0.363205        0.027881   \n",
       "5       11.860507      0.753991         0.511605        0.006749   \n",
       "6        7.064764      0.429133         0.292892        0.012961   \n",
       "7       11.278615      0.050621         0.449117        0.006766   \n",
       "8       15.016027      0.072746         0.609230        0.011045   \n",
       "9        5.115995      0.458709         0.187456        0.015621   \n",
       "10       7.798960      0.542535         0.285100        0.023094   \n",
       "11      10.065815      0.243680         0.339774        0.012955   \n",
       "12       7.269990      0.628429         0.258173        0.031692   \n",
       "13      12.120765      0.830377         0.429572        0.035783   \n",
       "14      14.585749      1.422950         0.538901        0.099106   \n",
       "15       7.435436      0.317254         0.257725        0.007813   \n",
       "16      11.199969      0.269860         0.413954        0.032208   \n",
       "17      17.705971      0.608757         0.581871        0.023083   \n",
       "\n",
       "   param_criterion param_max_depth param_n_estimators param_random_state  \\\n",
       "0             gini              15                 50                  0   \n",
       "1             gini              15                 75                  0   \n",
       "2             gini              15                100                  0   \n",
       "3             gini              20                 50                  0   \n",
       "4             gini              20                 75                  0   \n",
       "5             gini              20                100                  0   \n",
       "6             gini              25                 50                  0   \n",
       "7             gini              25                 75                  0   \n",
       "8             gini              25                100                  0   \n",
       "9          entropy              15                 50                  0   \n",
       "10         entropy              15                 75                  0   \n",
       "11         entropy              15                100                  0   \n",
       "12         entropy              20                 50                  0   \n",
       "13         entropy              20                 75                  0   \n",
       "14         entropy              20                100                  0   \n",
       "15         entropy              25                 50                  0   \n",
       "16         entropy              25                 75                  0   \n",
       "17         entropy              25                100                  0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 15, 'n_esti...           0.559410   \n",
       "1   {'criterion': 'gini', 'max_depth': 15, 'n_esti...           0.561902   \n",
       "2   {'criterion': 'gini', 'max_depth': 15, 'n_esti...           0.562710   \n",
       "3   {'criterion': 'gini', 'max_depth': 20, 'n_esti...           0.565607   \n",
       "4   {'criterion': 'gini', 'max_depth': 20, 'n_esti...           0.568032   \n",
       "5   {'criterion': 'gini', 'max_depth': 20, 'n_esti...           0.569110   \n",
       "6   {'criterion': 'gini', 'max_depth': 25, 'n_esti...           0.566483   \n",
       "7   {'criterion': 'gini', 'max_depth': 25, 'n_esti...           0.568840   \n",
       "8   {'criterion': 'gini', 'max_depth': 25, 'n_esti...           0.571063   \n",
       "9   {'criterion': 'entropy', 'max_depth': 15, 'n_e...           0.553887   \n",
       "10  {'criterion': 'entropy', 'max_depth': 15, 'n_e...           0.557457   \n",
       "11  {'criterion': 'entropy', 'max_depth': 15, 'n_e...           0.559949   \n",
       "12  {'criterion': 'entropy', 'max_depth': 20, 'n_e...           0.559477   \n",
       "13  {'criterion': 'entropy', 'max_depth': 20, 'n_e...           0.563654   \n",
       "14  {'criterion': 'entropy', 'max_depth': 20, 'n_e...           0.565674   \n",
       "15  {'criterion': 'entropy', 'max_depth': 25, 'n_e...           0.562778   \n",
       "16  {'criterion': 'entropy', 'max_depth': 25, 'n_e...           0.568032   \n",
       "17  {'criterion': 'entropy', 'max_depth': 25, 'n_e...           0.568099   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.560189           0.558639           0.556416         0.558664   \n",
       "1            0.562883           0.561401           0.561401         0.561897   \n",
       "2            0.562748           0.562883           0.561132         0.562368   \n",
       "3            0.563355           0.567868           0.563826         0.565164   \n",
       "4            0.569485           0.570562           0.563355         0.567858   \n",
       "5            0.571371           0.572044           0.568205         0.570182   \n",
       "6            0.564904           0.564837           0.561334         0.564389   \n",
       "7            0.570967           0.570226           0.563759         0.568448   \n",
       "8            0.575076           0.570293           0.567262         0.570923   \n",
       "9            0.554665           0.560458           0.552240         0.555312   \n",
       "10           0.557966           0.563422           0.558302         0.559287   \n",
       "11           0.560997           0.565173           0.560121         0.561560   \n",
       "12           0.561603           0.562479           0.559380         0.560735   \n",
       "13           0.566386           0.567599           0.564230         0.565467   \n",
       "14           0.568070           0.567060           0.563894         0.566174   \n",
       "15           0.563085           0.563624           0.561469         0.562739   \n",
       "16           0.565376           0.569148           0.564365         0.566730   \n",
       "17           0.570293           0.571640           0.565039         0.568768   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.001408               17  \n",
       "1         0.000605               13  \n",
       "2         0.000717               12  \n",
       "3         0.001773                9  \n",
       "4         0.002751                5  \n",
       "5         0.001577                2  \n",
       "6         0.001883               10  \n",
       "7         0.002813                4  \n",
       "8         0.002787                1  \n",
       "9         0.003097               18  \n",
       "10        0.002406               16  \n",
       "11        0.002124               14  \n",
       "12        0.001343               15  \n",
       "13        0.001597                8  \n",
       "14        0.001568                7  \n",
       "15        0.000794               11  \n",
       "16        0.001934                6  \n",
       "17        0.002497                3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest (grid search)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "param = {\n",
    "    \"n_estimators\":[50,75,100],\n",
    "    \"criterion\":[\"gini\",\"entropy\"],\n",
    "    \"max_depth\":[15,20,25],\n",
    "    \"random_state\":[0],\n",
    "}\n",
    "gscv = GridSearchCV(RandomForestClassifier(), param, cv=4, verbose=2)\n",
    "gscv.fit(x, y)\n",
    "\n",
    "result = pd.DataFrame.from_dict(gscv.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=25, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest (train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=25)\n",
    "rf_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "filename = 'rf_clf.bin'\n",
    "pickle.dump(rf_clf, open(filename, 'wb'))\n",
    "\n",
    "# Load model\n",
    "#model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19760</th>\n",
       "      <td>79093</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19761</th>\n",
       "      <td>79099</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762</th>\n",
       "      <td>79102</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19763</th>\n",
       "      <td>79125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19764</th>\n",
       "      <td>79129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Response\n",
       "0          1         7\n",
       "1          3         8\n",
       "2          4         6\n",
       "3          9         8\n",
       "4         12         8\n",
       "...      ...       ...\n",
       "19760  79093         8\n",
       "19761  79099         8\n",
       "19762  79102         6\n",
       "19763  79125         2\n",
       "19764  79129         4\n",
       "\n",
       "[19765 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "result = rf_clf.predict(z)\n",
    "submission = pd.DataFrame({'Id': test['Id'].astype('int').values, 'Response': result})\n",
    "submission.to_csv('submission_rf.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "from tensorflow import keras\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[x.shape[-1]]),\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(9, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 4s 48ms/step - loss: 1.7307 - accuracy: 0.3840 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.5006 - accuracy: 0.4699 - val_loss: 1.3422 - val_accuracy: 0.5105\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.4062 - accuracy: 0.5017 - val_loss: 1.2932 - val_accuracy: 0.5341\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.3408 - accuracy: 0.5252 - val_loss: 1.2696 - val_accuracy: 0.5373\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.2959 - accuracy: 0.5444 - val_loss: 1.2684 - val_accuracy: 0.5355\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.2583 - accuracy: 0.5593 - val_loss: 1.2660 - val_accuracy: 0.5418\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.2244 - accuracy: 0.5731 - val_loss: 1.2811 - val_accuracy: 0.5361\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 1.1932 - accuracy: 0.5822 - val_loss: 1.2877 - val_accuracy: 0.5361\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.1572 - accuracy: 0.5979 - val_loss: 1.3030 - val_accuracy: 0.5335\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.1184 - accuracy: 0.6120 - val_loss: 1.3179 - val_accuracy: 0.5291\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.0818 - accuracy: 0.6264 - val_loss: 1.3606 - val_accuracy: 0.5265\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 1.0431 - accuracy: 0.6399 - val_loss: 1.3921 - val_accuracy: 0.5222\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 1.0003 - accuracy: 0.6586 - val_loss: 1.4605 - val_accuracy: 0.5222\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.9660 - accuracy: 0.6692 - val_loss: 1.4678 - val_accuracy: 0.5207\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.9335 - accuracy: 0.6814 - val_loss: 1.5413 - val_accuracy: 0.5111\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.8894 - accuracy: 0.6978 - val_loss: 1.6120 - val_accuracy: 0.5092\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.8485 - accuracy: 0.7102 - val_loss: 1.6394 - val_accuracy: 0.5147\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 0.8162 - accuracy: 0.7204 - val_loss: 1.7079 - val_accuracy: 0.5084\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 0.7851 - accuracy: 0.7326 - val_loss: 1.7994 - val_accuracy: 0.5098\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 0.7452 - accuracy: 0.7472 - val_loss: 1.9195 - val_accuracy: 0.5046\n"
     ]
    }
   ],
   "source": [
    "# DNN (fit and validation)\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 512\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train.values, y_train.values)).shuffle(len(x_train)).batch(batch_size)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val.values, y_val.values)).batch(batch_size)\n",
    "\n",
    "model = get_model()\n",
    "fit = model.fit(train_ds, validation_data=val_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DNN (accuracy by epoch)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fit.history['accuracy'])\n",
    "plt.plot(fit.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 1.6828 - accuracy: 0.4111\n",
      "Epoch 2/5\n",
      "116/116 [==============================] - 2s 14ms/step - loss: 1.4402 - accuracy: 0.4871\n",
      "Epoch 3/5\n",
      "116/116 [==============================] - 2s 14ms/step - loss: 1.3472 - accuracy: 0.5210\n",
      "Epoch 4/5\n",
      "116/116 [==============================] - 2s 14ms/step - loss: 1.2986 - accuracy: 0.5380\n",
      "Epoch 5/5\n",
      "116/116 [==============================] - 2s 13ms/step - loss: 1.2585 - accuracy: 0.5543\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19760</th>\n",
       "      <td>79093</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19761</th>\n",
       "      <td>79099</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762</th>\n",
       "      <td>79102</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19763</th>\n",
       "      <td>79125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19764</th>\n",
       "      <td>79129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Response\n",
       "0          1         1\n",
       "1          3         6\n",
       "2          4         6\n",
       "3          9         8\n",
       "4         12         8\n",
       "...      ...       ...\n",
       "19760  79093         8\n",
       "19761  79099         8\n",
       "19762  79102         6\n",
       "19763  79125         2\n",
       "19764  79129         4\n",
       "\n",
       "[19765 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x.values, y.values)).shuffle(len(x_train)).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((z.values)).batch(batch_size)\n",
    "\n",
    "# Train\n",
    "model = get_model()\n",
    "model.fit(train_ds, epochs=5)\n",
    "\n",
    "# Inference\n",
    "result = model.predict(test_ds)\n",
    "result = [pd.np.argmax(res) for res in result]\n",
    "submission = pd.DataFrame({'Id': test['Id'].astype('int').values, 'Response': result})\n",
    "submission.to_csv('submission_dnn.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnn_clf = tf.estimator.DNNClassifier(\n",
    "    feature_columns=x_train.columns,\n",
    "    hidden_units=[512, 256, 128, 64, 32],\n",
    "    n_classes=8)\n",
    "def input_fn(features, )\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
