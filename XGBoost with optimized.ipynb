{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xgboost as xgb\n",
    "from scipy.optimize import fmin_powell\n",
    "from ml_metrics import quadratic_weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return quadratic_weighted_kappa(yhat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "    \n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"     \n",
    "    params[\"eta\"] = 0.05\n",
    "    params[\"min_child_weight\"] = 360\n",
    "    params[\"subsample\"] = 0.85\n",
    "    params[\"colsample_bytree\"] = 0.3\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 7\n",
    "    plst = list(params.items())\n",
    "\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_offset(data, bin_offset, sv, scorer=eval_wrapper):\n",
    "    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n",
    "    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n",
    "    score = scorer(data[1], data[2])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_offsets(data, offsets):\n",
    "    for j in range(num_classes):\n",
    "        data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "columns_to_drop = ['Id', 'Response'] #, 'Medical_History_10','Medical_History_24']\n",
    "xgb_num_rounds = 720\n",
    "num_classes = 8\n",
    "missing_indicator = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data using pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsipl1494\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "print(\"Load the data using pandas\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# combine train and test\n",
    "all_data = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create any new variables    \n",
    "all_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\n",
    "all_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminate missing values\n"
     ]
    }
   ],
   "source": [
    "# factorize categorical variables\n",
    "all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n",
    "all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\n",
    "all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n",
    "\n",
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n",
    "\n",
    "print('Eliminate missing values')    \n",
    "all_data.fillna(missing_indicator, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the dtype on the label column\n",
    "all_data['Response'] = all_data['Response'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "train = all_data[all_data['Response']>0].copy()\n",
    "test = all_data[all_data['Response']<1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to xgb data structure\n",
    "xgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['Response'].values, missing=missing_indicator)\n",
    "xgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test['Response'].values, missing=missing_indicator)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('objective', 'reg:linear'), ('eta', 0.05), ('min_child_weight', 360), ('subsample', 0.85), ('colsample_bytree', 0.3), ('silent', 1), ('max_depth', 7)]\n"
     ]
    }
   ],
   "source": [
    "# get the parameters for xgboost\n",
    "plst = get_params()\n",
    "print(plst)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model = xgb.train(plst, xgtrain, xgb_num_rounds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is: 0.6515752806586164\n"
     ]
    }
   ],
   "source": [
    "# get preds\n",
    "train_preds = model.predict(xgtrain, ntree_limit=model.best_iteration)\n",
    "print('Train score is:', eval_wrapper(train_preds, train['Response'])) \n",
    "test_preds = model.predict(xgtest, ntree_limit=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset Train score is: 0.7039291534748933\n"
     ]
    }
   ],
   "source": [
    "# train offsets \n",
    "offsets = np.array([0.1, -1, -2, -1, -0.8, 0.02, 0.8, 1])\n",
    "offset_preds = np.vstack((train_preds, train_preds, train['Response'].values))\n",
    "offset_preds = apply_offsets(offset_preds, offsets)\n",
    "opt_order = [6,4,5,3]\n",
    "for j in opt_order:\n",
    "    train_offset = lambda x: -score_offset(offset_preds, x, j) * 100\n",
    "    offsets[j] = fmin_powell(train_offset, offsets[j], disp=False)\n",
    "\n",
    "print('Offset Train score is:', eval_wrapper(offset_preds[1], train['Response'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply offsets to test\n",
    "data = np.vstack((test_preds, test_preds, test['Response'].values))\n",
    "data = apply_offsets(data, offsets)\n",
    "\n",
    "final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out = pd.DataFrame({\"Id\": test['Id'].values, \"Response\": final_test_preds})\n",
    "preds_out = preds_out.set_index('Id')\n",
    "preds_out.to_csv('xgb_offset_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
